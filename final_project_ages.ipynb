{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[11:15] ] \n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1902)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.47  21.44  10.93  11.33]\n",
      " [ 11.01  21.3   10.48  17.18]\n",
      " [ 11.36  25.88  11.01  10.28]\n",
      " ..., \n",
      " [ 11.81  20.96   9.53  20.73]\n",
      " [ 17.16  30.01  14.73  10.42]\n",
      " [ 12.99  25.21  11.63  12.12]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629863301788\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.59      0.69      1306\n",
      "          1       0.44      0.71      0.55       596\n",
      "\n",
      "avg / total       0.70      0.63      0.64      1902\n",
      "\n",
      "[[772 534]\n",
      " [170 426]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68927444795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80      1306\n",
      "          1       0.51      0.20      0.28       596\n",
      "\n",
      "avg / total       0.65      0.69      0.64      1902\n",
      "\n",
      "[[1194  112]\n",
      " [ 479  117]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685594111462\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.80      1306\n",
      "          1       0.50      0.17      0.25       596\n",
      "\n",
      "avg / total       0.64      0.69      0.63      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.68559411,  0.68559411]),\n",
       " 'FDR': array([ 0.29176471,  0.5049505 ]),\n",
       " 'FNR': array([ 0.07810107,  0.83221477]),\n",
       " 'FPR': array([ 0.83221477,  0.07810107]),\n",
       " 'NPV': array([ 0.4950495 ,  0.70823529]),\n",
       " 'PPV': array([ 0.70823529,  0.4950495 ]),\n",
       " 'TNR': array([ 0.16778523,  0.92189893]),\n",
       " 'TPR': array([ 0.92189893,  0.16778523])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68927444795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80      1306\n",
      "          1       0.51      0.20      0.28       596\n",
      "\n",
      "avg / total       0.65      0.69      0.64      1902\n",
      "\n",
      "[[1194  112]\n",
      " [ 479  117]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680862250263\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.97      0.81      1306\n",
      "          1       0.40      0.04      0.07       596\n",
      "\n",
      "avg / total       0.60      0.68      0.58      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.68086225,  0.68086225]),\n",
       " 'FDR': array([ 0.31077423,  0.6       ]),\n",
       " 'FNR': array([ 0.02526799,  0.96308725]),\n",
       " 'FPR': array([ 0.96308725,  0.02526799]),\n",
       " 'NPV': array([ 0.4       ,  0.68922577]),\n",
       " 'PPV': array([ 0.68922577,  0.4       ]),\n",
       " 'TNR': array([ 0.03691275,  0.97473201]),\n",
       " 'TPR': array([ 0.97473201,  0.03691275])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 4))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df2 = df2.drop(['fold'], axis=1)\n",
    "df2 = df2[['agePct12t21','agePct12t29','agePct16t24','agePct65up']]\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>11.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>17.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>12.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.09</td>\n",
       "      <td>32.89</td>\n",
       "      <td>20.04</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.17</td>\n",
       "      <td>27.41</td>\n",
       "      <td>12.76</td>\n",
       "      <td>14.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.31</td>\n",
       "      <td>27.93</td>\n",
       "      <td>14.78</td>\n",
       "      <td>14.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.64</td>\n",
       "      <td>35.16</td>\n",
       "      <td>20.33</td>\n",
       "      <td>8.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.88</td>\n",
       "      <td>34.55</td>\n",
       "      <td>21.62</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agePct12t21  agePct12t29  agePct16t24  agePct65up\n",
       "0        12.47        21.44        10.93       11.33\n",
       "1        11.01        21.30        10.48       17.18\n",
       "2        11.36        25.88        11.01       10.28\n",
       "3        12.55        25.20        12.19       17.57\n",
       "4        24.46        40.53        28.69       12.65\n",
       "5        18.09        32.89        20.04       13.26\n",
       "6        11.17        27.41        12.76       14.42\n",
       "7        15.31        27.93        14.78       14.60\n",
       "8        16.64        35.16        20.33        8.58\n",
       "9        19.88        34.55        21.62       13.12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 4), (1994,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 4), (399, 4), (1595,), (399,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.71929825,  0.71929825]),\n",
       " 'FDR': array([ 0.22558923,  0.44117647]),\n",
       " 'FNR': array([ 0.16363636,  0.54032258]),\n",
       " 'FPR': array([ 0.54032258,  0.16363636]),\n",
       " 'NPV': array([ 0.55882353,  0.77441077]),\n",
       " 'PPV': array([ 0.77441077,  0.55882353]),\n",
       " 'TNR': array([ 0.45967742,  0.83636364]),\n",
       " 'TPR': array([ 0.83636364,  0.45967742])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Miniconda3\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 2 agePct16t24 (0.262121)\n",
      "2. feature 1 agePct12t29 (0.255903)\n",
      "3. feature 3 agePct65up (0.241549)\n",
      "4. feature 0 agePct12t21 (0.240427)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHoCAYAAACfNP0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFFIAALJSSAEAyEohBQAgqx/ysGT34vlk0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x829fc30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "#X_arr = feature_matrix_clean\n",
    "#y_arr = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#num_attributes = len(X_arr[0])\n",
    "top_x = 4 # just get top 4\n",
    "for f in range(top_x):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], df2.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_x), importances[indices[:top_x]],\n",
    "       color=\"r\", yerr=std[indices[:top_x]], align=\"center\")\n",
    "plt.xticks(range(top_x), [df2.columns[indices[i]] for i in range(top_x)])\n",
    "plt.xlim([-1, top_x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705616850552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.84      0.80      1362\n",
      "       True       0.55      0.42      0.47       632\n",
      "\n",
      "avg / total       0.69      0.71      0.69      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.70561685,  0.70561685]),\n",
       " 'FDR': array([ 0.24388632,  0.45322245]),\n",
       " 'FNR': array([ 0.16005874,  0.58386076]),\n",
       " 'FPR': array([ 0.58386076,  0.16005874]),\n",
       " 'NPV': array([ 0.54677755,  0.75611368]),\n",
       " 'PPV': array([ 0.75611368,  0.54677755]),\n",
       " 'TNR': array([ 0.41613924,  0.83994126]),\n",
       " 'TPR': array([ 0.83994126,  0.41613924])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR, 'Accuracy':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6855941114616193,\n",
       " 'false discovery': 0.50495049504950495,\n",
       " 'false negative': 0.83221476510067116,\n",
       " 'false positive': 0.078101071975497705,\n",
       " 'negative predictive val': 0.70823529411764707,\n",
       " 'precision': 0.49504950495049505,\n",
       " 'true negative': 0.92189892802450235,\n",
       " 'true positive': 0.16778523489932887}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.68559411,  0.68559411]),\n",
       " 'FDR': array([ 0.29176471,  0.5049505 ]),\n",
       " 'FNR': array([ 0.07810107,  0.83221477]),\n",
       " 'FPR': array([ 0.83221477,  0.07810107]),\n",
       " 'NPV': array([ 0.4950495 ,  0.70823529]),\n",
       " 'PPV': array([ 0.70823529,  0.4950495 ]),\n",
       " 'TNR': array([ 0.16778523,  0.92189893]),\n",
       " 'TPR': array([ 0.92189893,  0.16778523])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
