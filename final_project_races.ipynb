{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[7:11]]\n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1902)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.37  91.78   6.5    1.88]\n",
      " [  0.8   95.57   3.44   0.85]\n",
      " [  0.74  94.33   3.43   2.35]\n",
      " ..., \n",
      " [  0.52  92.62   0.98  11.  ]\n",
      " [  3.37  69.91   0.9   62.11]\n",
      " [  2.39  71.27   9.09  24.43]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808622502629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.90      0.87      1306\n",
      "          1       0.74      0.60      0.66       596\n",
      "\n",
      "avg / total       0.80      0.81      0.80      1902\n",
      "\n",
      "[[1179  127]\n",
      " [ 237  359]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825972660358\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88      1306\n",
      "          1       0.78      0.61      0.69       596\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1902\n",
      "\n",
      "[[1205  101]\n",
      " [ 230  366]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822818086225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88      1306\n",
      "          1       0.78      0.60      0.68       596\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.82281809,  0.82281809]),\n",
       " 'FDR': array([ 0.16470588,  0.2166302 ]),\n",
       " 'FNR': array([ 0.07580398,  0.39932886]),\n",
       " 'FPR': array([ 0.39932886,  0.07580398]),\n",
       " 'NPV': array([ 0.7833698 ,  0.83529412]),\n",
       " 'PPV': array([ 0.83529412,  0.7833698 ]),\n",
       " 'TNR': array([ 0.60067114,  0.92419602]),\n",
       " 'TPR': array([ 0.92419602,  0.60067114])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827549947424\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88      1306\n",
      "          1       0.78      0.62      0.69       596\n",
      "\n",
      "avg / total       0.82      0.83      0.82      1902\n",
      "\n",
      "[[1204  102]\n",
      " [ 226  370]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82334384858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88      1306\n",
      "          1       0.78      0.60      0.68       596\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.82334385,  0.82334385]),\n",
       " 'FDR': array([ 0.16412742,  0.21615721]),\n",
       " 'FNR': array([ 0.07580398,  0.39765101]),\n",
       " 'FPR': array([ 0.39765101,  0.07580398]),\n",
       " 'NPV': array([ 0.78384279,  0.83587258]),\n",
       " 'PPV': array([ 0.83587258,  0.78384279]),\n",
       " 'TNR': array([ 0.60234899,  0.92419602]),\n",
       " 'TPR': array([ 0.92419602,  0.60234899])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 4))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df2 = df2.drop(['fold'], axis=1)\n",
    "df2 = df2[['racePctWhite','racePctAsian','racepctblack','racePctHisp']]\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctHisp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.57</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84.87</td>\n",
       "      <td>0.40</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97.11</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>23.14</td>\n",
       "      <td>16.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   racePctWhite  racePctAsian  racepctblack  racePctHisp\n",
       "0         91.78          6.50          1.37         1.88\n",
       "1         95.57          3.44          0.80         0.85\n",
       "2         94.33          3.43          0.74         2.35\n",
       "3         97.35          0.50          1.70         0.70\n",
       "4         89.16          1.17          0.53         0.52\n",
       "5         95.65          0.90          2.51         0.95\n",
       "6         96.57          1.47          1.60         1.10\n",
       "7         84.87          0.40         14.20         0.63\n",
       "8         97.11          1.25          0.35         0.73\n",
       "9         67.60          0.92         23.14        16.35"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 4), (1994,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 4), (399, 4), (1595,), (399,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.81954887,  0.81954887]),\n",
       " 'FDR': array([ 0.12820513,  0.29365079]),\n",
       " 'FNR': array([ 0.13454545,  0.28225806]),\n",
       " 'FPR': array([ 0.28225806,  0.13454545]),\n",
       " 'NPV': array([ 0.70634921,  0.87179487]),\n",
       " 'PPV': array([ 0.87179487,  0.70634921]),\n",
       " 'TNR': array([ 0.71774194,  0.86545455]),\n",
       " 'TPR': array([ 0.86545455,  0.71774194])}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 0 racePctWhite (0.341413)\n",
      "2. feature 2 racepctblack (0.300599)\n",
      "3. feature 3 racePctHisp (0.197883)\n",
      "4. feature 1 racePctAsian (0.160105)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp0AAAHoCAYAAAAL0lTRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyka5aNBBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd28a4f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "#X_arr = feature_matrix_clean\n",
    "#y_arr = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#num_attributes = len(X_arr[0])\n",
    "top_x = 4 # just get top 4\n",
    "for f in range(top_x):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], df2.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_x), importances[indices[:top_x]],\n",
    "       color=\"r\", yerr=std[indices[:top_x]], align=\"center\")\n",
    "plt.xticks(range(top_x), [df2.columns[indices[i]] for i in range(top_x)])\n",
    "plt.xlim([-1, top_x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813440320963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.89      0.87      1362\n",
      "       True       0.73      0.65      0.69       632\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.81344032,  0.81344032]),\n",
       " 'FDR': array([ 0.15336134,  0.27031802]),\n",
       " 'FNR': array([ 0.1123348 ,  0.34651899]),\n",
       " 'FPR': array([ 0.34651899,  0.1123348 ]),\n",
       " 'NPV': array([ 0.72968198,  0.84663866]),\n",
       " 'PPV': array([ 0.84663866,  0.72968198]),\n",
       " 'TNR': array([ 0.65348101,  0.8876652 ]),\n",
       " 'TPR': array([ 0.8876652 ,  0.65348101])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR, 'Accuracy':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.82281808622502628,\n",
       " 'false discovery': 0.21663019693654267,\n",
       " 'false negative': 0.39932885906040266,\n",
       " 'false positive': 0.075803981623277186,\n",
       " 'negative predictive val': 0.83529411764705885,\n",
       " 'precision': 0.78336980306345738,\n",
       " 'true negative': 0.92419601837672283,\n",
       " 'true positive': 0.60067114093959728}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.82281809,  0.82281809]),\n",
       " 'FDR': array([ 0.16470588,  0.2166302 ]),\n",
       " 'FNR': array([ 0.07580398,  0.39932886]),\n",
       " 'FPR': array([ 0.39932886,  0.07580398]),\n",
       " 'NPV': array([ 0.7833698 ,  0.83529412]),\n",
       " 'PPV': array([ 0.83529412,  0.7833698 ]),\n",
       " 'TNR': array([ 0.60067114,  0.92419602]),\n",
       " 'TPR': array([ 0.92419602,  0.60067114])}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
