{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[43:56] ] \n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1902)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.67000000e+00   2.63800000e+01   5.22000000e+00 ...,   5.88800000e+01\n",
      "    3.10000000e+01   3.60000000e-01]\n",
      " [  4.23000000e+00   2.79900000e+01   6.45000000e+00 ...,   6.24300000e+01\n",
      "    4.30000000e+01   2.40000000e-01]\n",
      " [  1.01000000e+01   2.57800000e+01   1.47600000e+01 ...,   7.41900000e+01\n",
      "    1.64000000e+02   8.80000000e-01]\n",
      " ..., \n",
      " [  9.89000000e+00   2.05600000e+01   1.23800000e+01 ...,   6.26200000e+01\n",
      "    4.34000000e+02   1.60000000e+00]\n",
      " [  1.03500000e+01   2.91800000e+01   1.43600000e+01 ...,   6.01400000e+01\n",
      "    2.79000000e+02   2.35000000e+00]\n",
      " [  1.57700000e+01   2.97200000e+01   1.88400000e+01 ...,   5.73200000e+01\n",
      "    1.15200000e+03   4.85000000e+00]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835436382755\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.88      1306\n",
      "          1       0.77      0.68      0.72       596\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1902\n",
      "\n",
      "[[1185  121]\n",
      " [ 192  404]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856466876972\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90      1306\n",
      "          1       0.81      0.70      0.75       596\n",
      "\n",
      "avg / total       0.85      0.86      0.85      1902\n",
      "\n",
      "[[1210   96]\n",
      " [ 177  419]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854889589905\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.90      1306\n",
      "          1       0.81      0.70      0.75       596\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.85488959,  0.85488959]),\n",
       " 'FDR': array([ 0.12735166,  0.19230769]),\n",
       " 'FNR': array([ 0.07656968,  0.29530201]),\n",
       " 'FPR': array([ 0.29530201,  0.07656968]),\n",
       " 'NPV': array([ 0.80769231,  0.87264834]),\n",
       " 'PPV': array([ 0.87264834,  0.80769231]),\n",
       " 'TNR': array([ 0.70469799,  0.92343032]),\n",
       " 'TPR': array([ 0.92343032,  0.70469799])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856992639327\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.90      1306\n",
      "          1       0.81      0.71      0.76       596\n",
      "\n",
      "avg / total       0.85      0.86      0.85      1902\n",
      "\n",
      "[[1207   99]\n",
      " [ 173  423]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858044164038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      1306\n",
      "          1       0.81      0.72      0.76       596\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.85804416,  0.85804416]),\n",
       " 'FDR': array([ 0.12299854,  0.19128788]),\n",
       " 'FNR': array([ 0.07733538,  0.28355705]),\n",
       " 'FPR': array([ 0.28355705,  0.07733538]),\n",
       " 'NPV': array([ 0.80871212,  0.87700146]),\n",
       " 'PPV': array([ 0.87700146,  0.80871212]),\n",
       " 'TNR': array([ 0.71644295,  0.92266462]),\n",
       " 'TPR': array([ 0.92266462,  0.71644295])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 13))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df2 = df2.drop(['fold'], axis=1)\n",
    "df2 = df2.ix[:,37:50]\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumKidsBornNeverMar</th>\n",
       "      <th>PctKidsBornNeverMar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.67</td>\n",
       "      <td>26.38</td>\n",
       "      <td>5.22</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.22</td>\n",
       "      <td>91.43</td>\n",
       "      <td>90.17</td>\n",
       "      <td>95.78</td>\n",
       "      <td>95.81</td>\n",
       "      <td>44.56</td>\n",
       "      <td>58.88</td>\n",
       "      <td>31</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.23</td>\n",
       "      <td>27.99</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5.42</td>\n",
       "      <td>3.11</td>\n",
       "      <td>86.91</td>\n",
       "      <td>85.33</td>\n",
       "      <td>96.82</td>\n",
       "      <td>86.46</td>\n",
       "      <td>51.14</td>\n",
       "      <td>62.43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.10</td>\n",
       "      <td>25.78</td>\n",
       "      <td>14.76</td>\n",
       "      <td>12.55</td>\n",
       "      <td>2.95</td>\n",
       "      <td>78.54</td>\n",
       "      <td>78.85</td>\n",
       "      <td>92.37</td>\n",
       "      <td>75.72</td>\n",
       "      <td>66.08</td>\n",
       "      <td>74.19</td>\n",
       "      <td>164</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.98</td>\n",
       "      <td>28.15</td>\n",
       "      <td>14.47</td>\n",
       "      <td>12.91</td>\n",
       "      <td>2.98</td>\n",
       "      <td>64.02</td>\n",
       "      <td>62.36</td>\n",
       "      <td>65.38</td>\n",
       "      <td>67.43</td>\n",
       "      <td>59.59</td>\n",
       "      <td>70.27</td>\n",
       "      <td>561</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.51</td>\n",
       "      <td>50.66</td>\n",
       "      <td>11.64</td>\n",
       "      <td>9.73</td>\n",
       "      <td>2.98</td>\n",
       "      <td>58.59</td>\n",
       "      <td>55.20</td>\n",
       "      <td>66.51</td>\n",
       "      <td>79.17</td>\n",
       "      <td>61.22</td>\n",
       "      <td>68.94</td>\n",
       "      <td>402</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.40</td>\n",
       "      <td>33.32</td>\n",
       "      <td>14.46</td>\n",
       "      <td>13.04</td>\n",
       "      <td>2.89</td>\n",
       "      <td>71.94</td>\n",
       "      <td>69.79</td>\n",
       "      <td>79.76</td>\n",
       "      <td>75.33</td>\n",
       "      <td>62.96</td>\n",
       "      <td>70.52</td>\n",
       "      <td>1511</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.97</td>\n",
       "      <td>36.05</td>\n",
       "      <td>9.06</td>\n",
       "      <td>7.64</td>\n",
       "      <td>3.14</td>\n",
       "      <td>79.53</td>\n",
       "      <td>79.76</td>\n",
       "      <td>92.05</td>\n",
       "      <td>77.12</td>\n",
       "      <td>65.16</td>\n",
       "      <td>72.81</td>\n",
       "      <td>263</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.28</td>\n",
       "      <td>28.34</td>\n",
       "      <td>16.33</td>\n",
       "      <td>14.94</td>\n",
       "      <td>2.95</td>\n",
       "      <td>62.56</td>\n",
       "      <td>58.70</td>\n",
       "      <td>69.89</td>\n",
       "      <td>62.76</td>\n",
       "      <td>63.08</td>\n",
       "      <td>72.44</td>\n",
       "      <td>2368</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.29</td>\n",
       "      <td>40.87</td>\n",
       "      <td>9.94</td>\n",
       "      <td>8.64</td>\n",
       "      <td>3.00</td>\n",
       "      <td>79.35</td>\n",
       "      <td>79.70</td>\n",
       "      <td>86.60</td>\n",
       "      <td>80.70</td>\n",
       "      <td>74.32</td>\n",
       "      <td>78.51</td>\n",
       "      <td>751</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.07</td>\n",
       "      <td>38.49</td>\n",
       "      <td>14.66</td>\n",
       "      <td>12.97</td>\n",
       "      <td>3.11</td>\n",
       "      <td>61.65</td>\n",
       "      <td>54.56</td>\n",
       "      <td>68.85</td>\n",
       "      <td>61.69</td>\n",
       "      <td>60.80</td>\n",
       "      <td>69.23</td>\n",
       "      <td>3537</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MalePctDivorce  MalePctNevMarr  FemalePctDiv  TotalPctDiv  PersPerFam  \\\n",
       "0            3.67           26.38          5.22         4.47        3.22   \n",
       "1            4.23           27.99          6.45         5.42        3.11   \n",
       "2           10.10           25.78         14.76        12.55        2.95   \n",
       "3           10.98           28.15         14.47        12.91        2.98   \n",
       "4            7.51           50.66         11.64         9.73        2.98   \n",
       "5           11.40           33.32         14.46        13.04        2.89   \n",
       "6            5.97           36.05          9.06         7.64        3.14   \n",
       "7           13.28           28.34         16.33        14.94        2.95   \n",
       "8            7.29           40.87          9.94         8.64        3.00   \n",
       "9           11.07           38.49         14.66        12.97        3.11   \n",
       "\n",
       "   PctFam2Par  PctKids2Par  PctYoungKids2Par  PctTeen2Par  \\\n",
       "0       91.43        90.17             95.78        95.81   \n",
       "1       86.91        85.33             96.82        86.46   \n",
       "2       78.54        78.85             92.37        75.72   \n",
       "3       64.02        62.36             65.38        67.43   \n",
       "4       58.59        55.20             66.51        79.17   \n",
       "5       71.94        69.79             79.76        75.33   \n",
       "6       79.53        79.76             92.05        77.12   \n",
       "7       62.56        58.70             69.89        62.76   \n",
       "8       79.35        79.70             86.60        80.70   \n",
       "9       61.65        54.56             68.85        61.69   \n",
       "\n",
       "   PctWorkMomYoungKids  PctWorkMom  NumKidsBornNeverMar  PctKidsBornNeverMar  \n",
       "0                44.56       58.88                   31                 0.36  \n",
       "1                51.14       62.43                   43                 0.24  \n",
       "2                66.08       74.19                  164                 0.88  \n",
       "3                59.59       70.27                  561                 3.84  \n",
       "4                61.22       68.94                  402                 4.70  \n",
       "5                62.96       70.52                 1511                 1.58  \n",
       "6                65.16       72.81                  263                 1.18  \n",
       "7                63.08       72.44                 2368                 4.66  \n",
       "8                74.32       78.51                  751                 1.64  \n",
       "9                60.80       69.23                 3537                 4.71  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 13), (1994,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 13), (399, 13), (1595,), (399,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.84711779,  0.84711779]),\n",
       " 'FDR': array([ 0.12056738,  0.23076923]),\n",
       " 'FNR': array([ 0.09818182,  0.27419355]),\n",
       " 'FPR': array([ 0.27419355,  0.09818182]),\n",
       " 'NPV': array([ 0.76923077,  0.87943262]),\n",
       " 'PPV': array([ 0.87943262,  0.76923077]),\n",
       " 'TNR': array([ 0.72580645,  0.90181818]),\n",
       " 'TPR': array([ 0.90181818,  0.72580645])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 12 PctKidsBornNeverMar (0.140936)\n",
      "2. feature 6 PctKids2Par (0.138654)\n",
      "3. feature 5 PctFam2Par (0.100550)\n",
      "4. feature 7 PctYoungKids2Par (0.099901)\n",
      "5. feature 8 PctTeen2Par (0.082247)\n",
      "6. feature 2 FemalePctDiv (0.068302)\n",
      "7. feature 11 NumKidsBornNeverMar (0.065286)\n",
      "8. feature 3 TotalPctDiv (0.060750)\n",
      "9. feature 4 PersPerFam (0.060334)\n",
      "10. feature 0 MalePctDivorce (0.052459)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHoCAYAAACfNP0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERERERP5U/g+cd6VkljSL5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2441eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "#X_arr = feature_matrix_clean\n",
    "#y_arr = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#num_attributes = len(X_arr[0])\n",
    "top_x = 10 # just get top 10\n",
    "for f in range(top_x):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], df2.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_x), importances[indices[:top_x]],\n",
    "       color=\"r\", yerr=std[indices[:top_x]], align=\"center\")\n",
    "plt.xticks(range(top_x), [df2.columns[indices[i]] for i in range(top_x)])\n",
    "plt.xlim([-1, top_x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85406218656\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.92      0.90      1362\n",
      "       True       0.81      0.71      0.75       632\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.85406219,  0.85406219]),\n",
       " 'FDR': array([ 0.12889813,  0.19056261]),\n",
       " 'FNR': array([ 0.07709251,  0.2943038 ]),\n",
       " 'FPR': array([ 0.2943038 ,  0.07709251]),\n",
       " 'NPV': array([ 0.80943739,  0.87110187]),\n",
       " 'PPV': array([ 0.87110187,  0.80943739]),\n",
       " 'TNR': array([ 0.7056962 ,  0.92290749]),\n",
       " 'TPR': array([ 0.92290749,  0.7056962 ])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR, 'Accuracy':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.85488958990536279,\n",
       " 'false discovery': 0.19230769230769232,\n",
       " 'false negative': 0.29530201342281881,\n",
       " 'false positive': 0.076569678407350683,\n",
       " 'negative predictive val': 0.87264833574529665,\n",
       " 'precision': 0.80769230769230771,\n",
       " 'true negative': 0.92343032159264926,\n",
       " 'true positive': 0.70469798657718119}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.85488959,  0.85488959]),\n",
       " 'FDR': array([ 0.12735166,  0.19230769]),\n",
       " 'FNR': array([ 0.07656968,  0.29530201]),\n",
       " 'FPR': array([ 0.29530201,  0.07656968]),\n",
       " 'NPV': array([ 0.80769231,  0.87264834]),\n",
       " 'PPV': array([ 0.87264834,  0.80769231]),\n",
       " 'TNR': array([ 0.70469799,  0.92343032]),\n",
       " 'TPR': array([ 0.92343032,  0.70469799])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
