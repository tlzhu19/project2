{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[34:37] ] \n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1902)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.81   9.9   48.18]\n",
      " [  5.61  13.72  29.89]\n",
      " [  2.8    9.09  30.13]\n",
      " ..., \n",
      " [  7.82  26.14  12.42]\n",
      " [ 24.37  39.63  12.4 ]\n",
      " [ 13.93  33.68   8.86]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739747634069\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.83      0.81      1306\n",
      "          1       0.59      0.53      0.56       596\n",
      "\n",
      "avg / total       0.73      0.74      0.74      1902\n",
      "\n",
      "[[1089  217]\n",
      " [ 278  318]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757097791798\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.83      1306\n",
      "          1       0.66      0.47      0.55       596\n",
      "\n",
      "avg / total       0.75      0.76      0.74      1902\n",
      "\n",
      "[[1162  144]\n",
      " [ 318  278]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757097791798\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.83      1306\n",
      "          1       0.66      0.47      0.55       596\n",
      "\n",
      "avg / total       0.75      0.76      0.74      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.75709779,  0.75709779]),\n",
       " 'FDR': array([ 0.21486486,  0.34123223]),\n",
       " 'FNR': array([ 0.11026034,  0.53355705]),\n",
       " 'FPR': array([ 0.53355705,  0.11026034]),\n",
       " 'NPV': array([ 0.65876777,  0.78513514]),\n",
       " 'PPV': array([ 0.78513514,  0.65876777]),\n",
       " 'TNR': array([ 0.46644295,  0.88973966]),\n",
       " 'TPR': array([ 0.88973966,  0.46644295])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757097791798\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.83      1306\n",
      "          1       0.66      0.47      0.55       596\n",
      "\n",
      "avg / total       0.75      0.76      0.74      1902\n",
      "\n",
      "[[1162  144]\n",
      " [ 318  278]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753943217666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.89      0.83      1306\n",
      "          1       0.66      0.45      0.53       596\n",
      "\n",
      "avg / total       0.74      0.75      0.74      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.75394322,  0.75394322]),\n",
       " 'FDR': array([ 0.2191689 ,  0.34390244]),\n",
       " 'FNR': array([ 0.10796325,  0.54865772]),\n",
       " 'FPR': array([ 0.54865772,  0.10796325]),\n",
       " 'NPV': array([ 0.65609756,  0.7808311 ]),\n",
       " 'PPV': array([ 0.7808311 ,  0.65609756]),\n",
       " 'TNR': array([ 0.45134228,  0.89203675]),\n",
       " 'TPR': array([ 0.89203675,  0.45134228])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df2 = df2.drop(['fold'], axis=1)\n",
    "df2 = df2[['PctLess9thGrade','PctNotHSGrad','PctBSorMore']]\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.81</td>\n",
       "      <td>9.90</td>\n",
       "      <td>48.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.61</td>\n",
       "      <td>13.72</td>\n",
       "      <td>29.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.80</td>\n",
       "      <td>9.09</td>\n",
       "      <td>30.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.05</td>\n",
       "      <td>33.68</td>\n",
       "      <td>10.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.15</td>\n",
       "      <td>23.06</td>\n",
       "      <td>25.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.76</td>\n",
       "      <td>23.03</td>\n",
       "      <td>20.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.49</td>\n",
       "      <td>13.89</td>\n",
       "      <td>27.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.09</td>\n",
       "      <td>28.67</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.52</td>\n",
       "      <td>11.27</td>\n",
       "      <td>30.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.01</td>\n",
       "      <td>31.62</td>\n",
       "      <td>17.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PctLess9thGrade  PctNotHSGrad  PctBSorMore\n",
       "0             5.81          9.90        48.18\n",
       "1             5.61         13.72        29.89\n",
       "2             2.80          9.09        30.13\n",
       "3            11.05         33.68        10.81\n",
       "4            12.15         23.06        25.28\n",
       "5             8.76         23.03        20.66\n",
       "6             4.49         13.89        27.01\n",
       "7            10.09         28.67        12.00\n",
       "8             5.52         11.27        30.24\n",
       "9            13.01         31.62        17.02"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 3), (1994,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 3), (399, 3), (1595,), (399,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.74185464,  0.74185464]),\n",
       " 'FDR': array([ 0.20945946,  0.39805825]),\n",
       " 'FNR': array([ 0.14909091,  0.5       ]),\n",
       " 'FPR': array([ 0.5       ,  0.14909091]),\n",
       " 'NPV': array([ 0.60194175,  0.79054054]),\n",
       " 'PPV': array([ 0.79054054,  0.60194175]),\n",
       " 'TNR': array([ 0.5       ,  0.85090909]),\n",
       " 'TPR': array([ 0.85090909,  0.5       ])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 PctNotHSGrad (0.393665)\n",
      "2. feature 0 PctLess9thGrade (0.322157)\n",
      "3. feature 2 PctBSorMore (0.284177)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHoCAYAAACfNP0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCIhFQRBEARBEDqUSEgFQRAEQRCEDvV/MpolbIXJZJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2189a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "#X_arr = feature_matrix_clean\n",
    "#y_arr = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#num_attributes = len(X_arr[0])\n",
    "top_x = 3 # just get top 3\n",
    "for f in range(top_x):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], df2.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_x), importances[indices[:top_x]],\n",
    "       color=\"r\", yerr=std[indices[:top_x]], align=\"center\")\n",
    "plt.xticks(range(top_x), [df2.columns[indices[i]] for i in range(top_x)])\n",
    "plt.xlim([-1, top_x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732698094283\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.85      0.81      1362\n",
      "       True       0.60      0.47      0.53       632\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.73269809,  0.73269809]),\n",
       " 'FDR': array([ 0.22274247,  0.4008016 ]),\n",
       " 'FNR': array([ 0.14684288,  0.52689873]),\n",
       " 'FPR': array([ 0.52689873,  0.14684288]),\n",
       " 'NPV': array([ 0.5991984 ,  0.77725753]),\n",
       " 'PPV': array([ 0.77725753,  0.5991984 ]),\n",
       " 'TNR': array([ 0.47310127,  0.85315712]),\n",
       " 'TPR': array([ 0.85315712,  0.47310127])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR, 'Accuracy':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.75709779179810721,\n",
       " 'false discovery': 0.34123222748815168,\n",
       " 'false negative': 0.53355704697986572,\n",
       " 'false positive': 0.11026033690658499,\n",
       " 'negative predictive val': 0.78513513513513511,\n",
       " 'precision': 0.65876777251184837,\n",
       " 'true negative': 0.88973966309341501,\n",
       " 'true positive': 0.46644295302013422}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.75709779,  0.75709779]),\n",
       " 'FDR': array([ 0.21486486,  0.34123223]),\n",
       " 'FNR': array([ 0.11026034,  0.53355705]),\n",
       " 'FPR': array([ 0.53355705,  0.11026034]),\n",
       " 'NPV': array([ 0.65876777,  0.78513514]),\n",
       " 'PPV': array([ 0.78513514,  0.65876777]),\n",
       " 'TNR': array([ 0.46644295,  0.88973966]),\n",
       " 'TPR': array([ 0.88973966,  0.46644295])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
