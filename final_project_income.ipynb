{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[17:26] ] \n",
    "    features += [ f for f in features_orig[32:34] ] \n",
    "    features += [ f for f in features_orig[37:39] ] \n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1902)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.51220000e+04   8.92400000e+01   1.55000000e+00 ...,   1.96000000e+00\n",
      "    2.70000000e+00   6.45500000e+01]\n",
      " [  4.79170000e+04   7.89900000e+01   1.11000000e+00 ...,   3.98000000e+00\n",
      "    2.43000000e+00   6.19600000e+01]\n",
      " [  3.56690000e+04   8.20000000e+01   1.15000000e+00 ...,   4.75000000e+00\n",
      "    4.01000000e+00   6.98000000e+01]\n",
      " ..., \n",
      " [  2.71820000e+04   5.97900000e+01   5.10000000e-01 ...,   7.56000000e+00\n",
      "    5.18000000e+00   5.05400000e+01]\n",
      " [  1.98990000e+04   7.16700000e+01   1.70000000e+00 ...,   3.03200000e+01\n",
      "    1.21200000e+01   5.25300000e+01]\n",
      " [  2.32870000e+04   6.88900000e+01   1.20000000e+00 ...,   1.85000000e+01\n",
      "    9.27000000e+00   5.33500000e+01]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793901156677\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.82      0.84      1306\n",
      "          1       0.65      0.75      0.69       596\n",
      "\n",
      "avg / total       0.80      0.79      0.80      1902\n",
      "\n",
      "[[1065  241]\n",
      " [ 151  445]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835436382755\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.88      1306\n",
      "          1       0.77      0.67      0.72       596\n",
      "\n",
      "avg / total       0.83      0.84      0.83      1902\n",
      "\n",
      "[[1190  116]\n",
      " [ 197  399]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831756046267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.88      1306\n",
      "          1       0.77      0.66      0.71       596\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.83175605,  0.83175605]),\n",
       " 'FDR': array([ 0.14481268,  0.23151751]),\n",
       " 'FNR': array([ 0.09111792,  0.33724832]),\n",
       " 'FPR': array([ 0.33724832,  0.09111792]),\n",
       " 'NPV': array([ 0.76848249,  0.85518732]),\n",
       " 'PPV': array([ 0.85518732,  0.76848249]),\n",
       " 'TNR': array([ 0.66275168,  0.90888208]),\n",
       " 'TPR': array([ 0.90888208,  0.66275168])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832281808623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88      1306\n",
      "          1       0.78      0.65      0.71       596\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1902\n",
      "\n",
      "[[1193  113]\n",
      " [ 206  390]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829652996845\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88      1306\n",
      "          1       0.77      0.65      0.71       596\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.829653,  0.829653]),\n",
       " 'FDR': array([ 0.14777618,  0.23228346]),\n",
       " 'FNR': array([ 0.09035222,  0.34563758]),\n",
       " 'FPR': array([ 0.34563758,  0.09035222]),\n",
       " 'NPV': array([ 0.76771654,  0.85222382]),\n",
       " 'PPV': array([ 0.85222382,  0.76771654]),\n",
       " 'TNR': array([ 0.65436242,  0.90964778]),\n",
       " 'TPR': array([ 0.90964778,  0.65436242])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 13))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df2 = df2.drop(['fold'], axis=1)\n",
    "df2 = df2[[ 'medIncome', 'pctWWage','pctWFarmSelf','pctWInvInc','pctWSocSec','pctWPubAsst','pctWRetire',\n",
    "           'medFamInc','perCapInc','NumUnderPov','PctPopUnderPov','PctUnemployed','PctEmploy']]\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75122</td>\n",
       "      <td>89.24</td>\n",
       "      <td>1.55</td>\n",
       "      <td>70.20</td>\n",
       "      <td>23.62</td>\n",
       "      <td>1.03</td>\n",
       "      <td>18.39</td>\n",
       "      <td>79584</td>\n",
       "      <td>29711</td>\n",
       "      <td>227</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.70</td>\n",
       "      <td>64.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47917</td>\n",
       "      <td>78.99</td>\n",
       "      <td>1.11</td>\n",
       "      <td>64.11</td>\n",
       "      <td>35.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>22.85</td>\n",
       "      <td>55323</td>\n",
       "      <td>20148</td>\n",
       "      <td>885</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>61.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35669</td>\n",
       "      <td>82.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>55.73</td>\n",
       "      <td>22.25</td>\n",
       "      <td>2.94</td>\n",
       "      <td>14.56</td>\n",
       "      <td>42112</td>\n",
       "      <td>16946</td>\n",
       "      <td>1389</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.01</td>\n",
       "      <td>69.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20580</td>\n",
       "      <td>68.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>38.95</td>\n",
       "      <td>39.48</td>\n",
       "      <td>11.71</td>\n",
       "      <td>18.33</td>\n",
       "      <td>26501</td>\n",
       "      <td>10810</td>\n",
       "      <td>2831</td>\n",
       "      <td>17.23</td>\n",
       "      <td>9.86</td>\n",
       "      <td>54.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17390</td>\n",
       "      <td>69.33</td>\n",
       "      <td>0.55</td>\n",
       "      <td>42.82</td>\n",
       "      <td>32.16</td>\n",
       "      <td>11.21</td>\n",
       "      <td>14.43</td>\n",
       "      <td>24018</td>\n",
       "      <td>8483</td>\n",
       "      <td>2855</td>\n",
       "      <td>29.99</td>\n",
       "      <td>9.08</td>\n",
       "      <td>52.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21577</td>\n",
       "      <td>75.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>41.15</td>\n",
       "      <td>29.31</td>\n",
       "      <td>7.12</td>\n",
       "      <td>14.09</td>\n",
       "      <td>27705</td>\n",
       "      <td>11878</td>\n",
       "      <td>23223</td>\n",
       "      <td>17.78</td>\n",
       "      <td>5.72</td>\n",
       "      <td>59.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42805</td>\n",
       "      <td>79.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>47.70</td>\n",
       "      <td>30.23</td>\n",
       "      <td>5.41</td>\n",
       "      <td>17.23</td>\n",
       "      <td>50394</td>\n",
       "      <td>18193</td>\n",
       "      <td>1126</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.85</td>\n",
       "      <td>65.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23221</td>\n",
       "      <td>71.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>35.74</td>\n",
       "      <td>32.58</td>\n",
       "      <td>8.81</td>\n",
       "      <td>22.59</td>\n",
       "      <td>28901</td>\n",
       "      <td>12161</td>\n",
       "      <td>10320</td>\n",
       "      <td>17.98</td>\n",
       "      <td>8.19</td>\n",
       "      <td>56.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25326</td>\n",
       "      <td>83.69</td>\n",
       "      <td>2.93</td>\n",
       "      <td>47.11</td>\n",
       "      <td>19.30</td>\n",
       "      <td>4.21</td>\n",
       "      <td>10.31</td>\n",
       "      <td>34269</td>\n",
       "      <td>13554</td>\n",
       "      <td>9603</td>\n",
       "      <td>13.68</td>\n",
       "      <td>4.18</td>\n",
       "      <td>68.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17852</td>\n",
       "      <td>74.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>30.98</td>\n",
       "      <td>29.09</td>\n",
       "      <td>9.06</td>\n",
       "      <td>13.99</td>\n",
       "      <td>24058</td>\n",
       "      <td>10195</td>\n",
       "      <td>27767</td>\n",
       "      <td>28.68</td>\n",
       "      <td>8.39</td>\n",
       "      <td>51.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medIncome  pctWWage  pctWFarmSelf  pctWInvInc  pctWSocSec  pctWPubAsst  \\\n",
       "0      75122     89.24          1.55       70.20       23.62         1.03   \n",
       "1      47917     78.99          1.11       64.11       35.50         2.75   \n",
       "2      35669     82.00          1.15       55.73       22.25         2.94   \n",
       "3      20580     68.15          0.24       38.95       39.48        11.71   \n",
       "4      17390     69.33          0.55       42.82       32.16        11.21   \n",
       "5      21577     75.78          1.00       41.15       29.31         7.12   \n",
       "6      42805     79.47          0.39       47.70       30.23         5.41   \n",
       "7      23221     71.60          0.67       35.74       32.58         8.81   \n",
       "8      25326     83.69          2.93       47.11       19.30         4.21   \n",
       "9      17852     74.20          0.86       30.98       29.09         9.06   \n",
       "\n",
       "   pctWRetire  medFamInc  perCapInc  NumUnderPov  PctPopUnderPov  \\\n",
       "0       18.39      79584      29711          227            1.96   \n",
       "1       22.85      55323      20148          885            3.98   \n",
       "2       14.56      42112      16946         1389            4.75   \n",
       "3       18.33      26501      10810         2831           17.23   \n",
       "4       14.43      24018       8483         2855           29.99   \n",
       "5       14.09      27705      11878        23223           17.78   \n",
       "6       17.23      50394      18193         1126            4.01   \n",
       "7       22.59      28901      12161        10320           17.98   \n",
       "8       10.31      34269      13554         9603           13.68   \n",
       "9       13.99      24058      10195        27767           28.68   \n",
       "\n",
       "   PctUnemployed  PctEmploy  \n",
       "0           2.70      64.55  \n",
       "1           2.43      61.96  \n",
       "2           4.01      69.80  \n",
       "3           9.86      54.74  \n",
       "4           9.08      52.44  \n",
       "5           5.72      59.02  \n",
       "6           4.85      65.42  \n",
       "7           8.19      56.59  \n",
       "8           4.18      68.51  \n",
       "9           8.39      51.37  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 13)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 13), (1994,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 13), (399, 13), (1595,), (399,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.85463659,  0.85463659]),\n",
       " 'FDR': array([ 0.12714777,  0.19444444]),\n",
       " 'FNR': array([ 0.07636364,  0.2983871 ]),\n",
       " 'FPR': array([ 0.2983871 ,  0.07636364]),\n",
       " 'NPV': array([ 0.80555556,  0.87285223]),\n",
       " 'PPV': array([ 0.87285223,  0.80555556]),\n",
       " 'TNR': array([ 0.7016129 ,  0.92363636]),\n",
       " 'TPR': array([ 0.92363636,  0.7016129 ])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 3 pctWInvInc (0.144623)\n",
      "2. feature 10 PctPopUnderPov (0.127838)\n",
      "3. feature 5 pctWPubAsst (0.124260)\n",
      "4. feature 9 NumUnderPov (0.084872)\n",
      "5. feature 11 PctUnemployed (0.073861)\n",
      "6. feature 7 medFamInc (0.066305)\n",
      "7. feature 8 perCapInc (0.061857)\n",
      "8. feature 0 medIncome (0.060766)\n",
      "9. feature 12 PctEmploy (0.054156)\n",
      "10. feature 1 pctWWage (0.051553)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAHoCAYAAACfNP0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERJ4q/wcEBl0WBE4cTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f16230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "#X_arr = feature_matrix_clean\n",
    "#y_arr = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#num_attributes = len(X_arr[0])\n",
    "top_x = 10 # just get top 10\n",
    "for f in range(top_x):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], df2.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_x), importances[indices[:top_x]],\n",
    "       color=\"r\", yerr=std[indices[:top_x]], align=\"center\")\n",
    "plt.xticks(range(top_x), [df2.columns[indices[i]] for i in range(top_x)])\n",
    "plt.xlim([-1, top_x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832998996991\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.86      0.91      0.88      1362\n",
      "       True       0.77      0.67      0.72       632\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.832999,  0.832999]),\n",
       " 'FDR': array([ 0.14295628,  0.22965642]),\n",
       " 'FNR': array([ 0.09324523,  0.32594937]),\n",
       " 'FPR': array([ 0.32594937,  0.09324523]),\n",
       " 'NPV': array([ 0.77034358,  0.85704372]),\n",
       " 'PPV': array([ 0.85704372,  0.77034358]),\n",
       " 'TNR': array([ 0.67405063,  0.90675477]),\n",
       " 'TPR': array([ 0.90675477,  0.67405063])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR, 'Accuracy':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.83175604626708732,\n",
       " 'false discovery': 0.23151750972762647,\n",
       " 'false negative': 0.33724832214765099,\n",
       " 'false positive': 0.091117917304747317,\n",
       " 'negative predictive val': 0.85518731988472618,\n",
       " 'precision': 0.76848249027237359,\n",
       " 'true negative': 0.90888208269525272,\n",
       " 'true positive': 0.66275167785234901}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.83175605,  0.83175605]),\n",
       " 'FDR': array([ 0.14481268,  0.23151751]),\n",
       " 'FNR': array([ 0.09111792,  0.33724832]),\n",
       " 'FPR': array([ 0.33724832,  0.09111792]),\n",
       " 'NPV': array([ 0.76848249,  0.85518732]),\n",
       " 'PPV': array([ 0.85518732,  0.76848249]),\n",
       " 'TNR': array([ 0.66275168,  0.90888208]),\n",
       " 'TPR': array([ 0.90888208,  0.66275168])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
