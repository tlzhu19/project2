{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_matrix = []\n",
    "target_vector1 = []\n",
    "target_vector2 = []\n",
    "varToNumNA = dict()\n",
    "\n",
    "for line in open('CommViolPredUnnormalizedData.txt', 'r'):\n",
    "    features_orig = line.strip().split(',')\n",
    "    for i in range(len(features_orig)):\n",
    "        if features_orig[i] == '?':\n",
    "            try:\n",
    "                varToNumNA[i] += 1\n",
    "            except:\n",
    "                varToNumNA[i] = 1\n",
    "    \n",
    "    target1 = features_orig[-2] # ViolentCrimesPerPop\n",
    "    target2 = features_orig[-1] # nonViolPerPop\n",
    "    #features = [ f for f in features[3:-2]] # don't include town and state name\n",
    "    features = [ f for f in features_orig[4:103] ] #don't include 103\n",
    "    features += [f for f in features_orig[120:123]] #don't include 103-119, or 123\n",
    "    features += [features_orig[127]] \n",
    "    features += [f for f in features_orig[129:131]]\n",
    "    features += [f for f in features_orig[133:143]]\n",
    "    feature_matrix.append(features)\n",
    "    target_vector1.append(target1)\n",
    "    target_vector2.append(target2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "\n",
    "# http://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "def statistical_measures(confusion_matrix):\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'ACC':ACC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1221,\n",
       " 3: 1224,\n",
       " 30: 1,\n",
       " 103: 1872,\n",
       " 104: 1872,\n",
       " 105: 1872,\n",
       " 106: 1872,\n",
       " 107: 1872,\n",
       " 108: 1872,\n",
       " 109: 1872,\n",
       " 110: 1872,\n",
       " 111: 1872,\n",
       " 112: 1872,\n",
       " 113: 1872,\n",
       " 114: 1872,\n",
       " 115: 1872,\n",
       " 116: 1872,\n",
       " 117: 1872,\n",
       " 118: 1872,\n",
       " 119: 1872,\n",
       " 123: 1872,\n",
       " 124: 1872,\n",
       " 125: 1872,\n",
       " 126: 1872,\n",
       " 128: 1872,\n",
       " 131: 208,\n",
       " 132: 208,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 13,\n",
       " 136: 13,\n",
       " 137: 3,\n",
       " 138: 3,\n",
       " 139: 3,\n",
       " 140: 3,\n",
       " 141: 3,\n",
       " 142: 3,\n",
       " 143: 91,\n",
       " 144: 91,\n",
       " 145: 221,\n",
       " 146: 97}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't use the variables that have a lot of '?'s in th data\n",
    "varToNumNA # {var : numNA}, var is the index of the variable, numNA is the nubmer of ?s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix[1]\n",
    "'?' in feature_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_clean = []\n",
    "target_vector1_clean = []\n",
    "target_vector2_clean = []\n",
    "for i in range(len(feature_matrix)):\n",
    "    if ('?' not in feature_matrix[i] and '?' not in target_vector1[i] and '?' not in target_vector2[i]):\n",
    "        feature_matrix_clean.append([float(x) for x in feature_matrix[i]])\n",
    "        target_vector1_clean.append(float(target_vector1[i]))\n",
    "        target_vector2_clean.append(float(target_vector2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 1901)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix), len(feature_matrix_clean) # get rid of some data ~300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVG_CRIME = 636.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.19800000e+04   3.10000000e+00 ...,   1.13208000e+03\n",
      "    1.60000000e+01   1.31260000e+02]\n",
      " [  1.00000000e+00   2.31230000e+04   2.82000000e+00 ...,   1.59878000e+03\n",
      "    2.60000000e+01   1.10550000e+02]\n",
      " [  1.00000000e+00   2.93440000e+04   2.43000000e+00 ...,   4.97219000e+03\n",
      "    1.36000000e+02   3.76300000e+02]\n",
      " ..., \n",
      " [  1.00000000e+01   3.28240000e+04   2.46000000e+00 ...,   2.43597000e+03\n",
      "    1.79000000e+02   4.87190000e+02]\n",
      " [  1.00000000e+01   1.35470000e+04   2.89000000e+00 ...,   3.72290000e+03\n",
      "    1.30000000e+01   1.02100000e+02]\n",
      " [  1.00000000e+01   2.88980000e+04   2.61000000e+00 ...,   4.81920000e+03\n",
      "    4.05000000e+02   1.33867000e+03]]\n",
      "[0 0 0 ..., 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data = np.array( feature_matrix_clean )\n",
    "target1 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean] )\n",
    "target2 = np.array( [ (1 if (x > AVG_CRIME) else 0) for x in target_vector2_clean] )\n",
    "\n",
    "print(data)\n",
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a variation of NB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "X_train, y_train1 = data, target1 \n",
    "model.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train) \n",
    "y_expected = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867964229353\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91      1305\n",
      "          1       0.90      0.65      0.76       596\n",
      "\n",
      "avg / total       0.87      0.87      0.86      1901\n",
      "\n",
      "[[1263   42]\n",
      " [ 209  387]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(y_expected, y_predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename, mode=\"rt\"):\n",
    "    # rt stands for \"read text\"\n",
    "    fin = contents = None\n",
    "    try:\n",
    "        fin = open(filename, mode)\n",
    "        contents = fin.read()\n",
    "    finally:\n",
    "        if (fin != None): fin.close()\n",
    "    return contents\n",
    "\n",
    "#def indexToName(i):\n",
    "#    contents = readFile('varNames.txt')\n",
    "#    contents_list = contents.split('\\n')\n",
    "#    contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#    return contents_list[i]\n",
    "\n",
    "# get all of the variable names\n",
    "contents = readFile('varNames.txt')\n",
    "contents_list = contents.split('\\n')\n",
    "contents_list = [ (s.split())[1][:-1] for s in contents_list ]\n",
    "#contents_list.index('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1221, 'countyCode'),\n",
       " (3, 1224, 'communityCode'),\n",
       " (30, 1, 'OtherPerCap'),\n",
       " (103, 1872, 'LemasSwornFT'),\n",
       " (104, 1872, 'LemasSwFTPerPop'),\n",
       " (105, 1872, 'LemasSwFTFieldOps'),\n",
       " (106, 1872, 'LemasSwFTFieldPerPop'),\n",
       " (107, 1872, 'LemasTotalReq'),\n",
       " (108, 1872, 'LemasTotReqPerPop'),\n",
       " (109, 1872, 'PolicReqPerOffic'),\n",
       " (110, 1872, 'PolicPerPop'),\n",
       " (111, 1872, 'RacialMatchCommPol'),\n",
       " (112, 1872, 'PctPolicWhite'),\n",
       " (113, 1872, 'PctPolicBlack'),\n",
       " (114, 1872, 'PctPolicHisp'),\n",
       " (115, 1872, 'PctPolicAsian'),\n",
       " (116, 1872, 'PctPolicMinor'),\n",
       " (117, 1872, 'OfficAssgnDrugUnits'),\n",
       " (118, 1872, 'NumKindsDrugsSeiz'),\n",
       " (119, 1872, 'PolicAveOTWorked'),\n",
       " (123, 1872, 'PolicCars'),\n",
       " (124, 1872, 'PolicOperBudg'),\n",
       " (125, 1872, 'LemasPctPolicOnPatr'),\n",
       " (126, 1872, 'LemasGangUnitDeploy'),\n",
       " (128, 1872, 'PolicBudgPerPop'),\n",
       " (131, 208, 'rapes'),\n",
       " (132, 208, 'rapesPerPop'),\n",
       " (133, 1, 'robberies'),\n",
       " (134, 1, 'robbbPerPop'),\n",
       " (135, 13, 'assaults'),\n",
       " (136, 13, 'assaultPerPop'),\n",
       " (137, 3, 'burglaries'),\n",
       " (138, 3, 'burglPerPop'),\n",
       " (139, 3, 'larcenies'),\n",
       " (140, 3, 'larcPerPop'),\n",
       " (141, 3, 'autoTheft'),\n",
       " (142, 3, 'autoTheftPerPop'),\n",
       " (143, 91, 'arsons'),\n",
       " (144, 91, 'arsonsPerPop'),\n",
       " (145, 221, 'ViolentCrimesPerPop'),\n",
       " (146, 97, 'nonViolPerPop')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varNames = []\n",
    "for i in varToNumNA:\n",
    "    varNames += [(i, varToNumNA[i], contents_list[i])]\n",
    "sorted(varNames) # variables that we didn't use: (index, # of times used, var name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "# use logistic reg and L1 penalty \n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1',)\n",
    "X = feature_matrix_clean\n",
    "y = [ (1 if (x > AVG_CRIME) else 0) for x in target_vector1_clean]\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992635455024\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      1305\n",
      "          1       0.99      0.98      0.99       596\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1901\n",
      "\n",
      "[[1301    4]\n",
      " [  10  586]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_log = logreg.predict(X)\n",
    "y_expected = y_train1\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97475013151\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1305\n",
      "          1       0.97      0.95      0.96       596\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w/ L1 penalty and CV\n",
    "from sklearn import cross_validation\n",
    "predicted = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l1'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.97475013,  0.97475013]),\n",
       " 'FDR': array([ 0.02132521,  0.03401361]),\n",
       " 'FNR': array([ 0.01532567,  0.04697987]),\n",
       " 'FPR': array([ 0.04697987,  0.01532567]),\n",
       " 'NPV': array([ 0.96598639,  0.97867479]),\n",
       " 'PPV': array([ 0.97867479,  0.96598639]),\n",
       " 'TNR': array([ 0.95302013,  0.98467433]),\n",
       " 'TPR': array([ 0.98467433,  0.95302013])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1 log reg, CV\n",
    "cm2 = confusion_matrix(y, predicted)\n",
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990005260389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      1305\n",
      "          1       0.99      0.98      0.98       596\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1901\n",
      "\n",
      "[[1299    6]\n",
      " [  13  583]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use logistic reg and L2 penalty \n",
    "logreg2 = linear_model.LogisticRegression(C=1e5, penalty='l2',)\n",
    "logreg2.fit(X, y)\n",
    "\n",
    "y_predicted_log2 = logreg2.predict(X)\n",
    "print(metrics.accuracy_score(y_expected, y_predicted_log2))\n",
    "print()\n",
    "print(metrics.classification_report(y_expected, y_predicted_log2))\n",
    "print(metrics.confusion_matrix(y_expected, y_predicted_log2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978432403998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1305\n",
      "          1       0.97      0.96      0.97       596\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_validation.cross_val_predict(linear_model.LogisticRegression(penalty='l2'), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted2))\n",
    "print(metrics.classification_report(y, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.9784324,  0.9784324]),\n",
       " 'FDR': array([ 0.01681957,  0.03204047]),\n",
       " 'FNR': array([ 0.01455939,  0.03691275]),\n",
       " 'FPR': array([ 0.03691275,  0.01455939]),\n",
       " 'NPV': array([ 0.96795953,  0.98318043]),\n",
       " 'PPV': array([ 0.98318043,  0.96795953]),\n",
       " 'TNR': array([ 0.96308725,  0.98544061]),\n",
       " 'TPR': array([ 0.98544061,  0.96308725])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 log reg, CV\n",
    "cm3 = confusion_matrix(y, predicted2)\n",
    "statistical_measures(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0   1   2      3    4      5     6     7      8    \\\n",
       "0  BerkeleyHeightstownship  NJ  39   5320    1  11980  3.10  1.37  91.78   \n",
       "1           Marpletownship  PA  45  47616    1  23123  2.82  0.80  95.57   \n",
       "2               Tigardcity  OR   ?      ?    1  29344  2.43  0.74  94.33   \n",
       "3         Gloversvillecity  NY  35  29443    1  16656  2.40  1.70  97.35   \n",
       "4              Bemidjicity  MN   7   5068    1  11245  2.76  0.53  89.16   \n",
       "\n",
       "    9     ...     137      138   139      140  141     142  143    144  \\\n",
       "0  6.50   ...      14   114.85   138  1132.08   16  131.26    2  16.41   \n",
       "1  3.44   ...      57   242.37   376  1598.78   26  110.55    1   4.25   \n",
       "2  3.43   ...     274   758.14  1797  4972.19  136   376.3   22  60.87   \n",
       "3  0.50   ...     225  1301.78   716  4142.56   47  271.93    ?      ?   \n",
       "4  1.17   ...      91   728.93  1060  8490.87   91  728.93    5  40.05   \n",
       "\n",
       "      145      146  \n",
       "0   41.02  1394.59  \n",
       "1  127.56  1955.95  \n",
       "2  218.59  6167.51  \n",
       "3  306.64        ?  \n",
       "4       ?  9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now try what we did in class on 5/2 (random forest and confusion matrix to analyze)\n",
    "df = pd.read_csv('CommViolPredUnnormalizedData.txt', header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>306.64</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5</td>\n",
       "      <td>40.05</td>\n",
       "      <td>?</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             communityname state countyCode communityCode  fold  population  \\\n",
       "0  BerkeleyHeightstownship    NJ         39          5320     1       11980   \n",
       "1           Marpletownship    PA         45         47616     1       23123   \n",
       "2               Tigardcity    OR          ?             ?     1       29344   \n",
       "3         Gloversvillecity    NY         35         29443     1       16656   \n",
       "4              Bemidjicity    MN          7          5068     1       11245   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian      ...        \\\n",
       "0           3.10          1.37         91.78          6.50      ...         \n",
       "1           2.82          0.80         95.57          3.44      ...         \n",
       "2           2.43          0.74         94.33          3.43      ...         \n",
       "3           2.40          1.70         97.35          0.50      ...         \n",
       "4           2.76          0.53         89.16          1.17      ...         \n",
       "\n",
       "   burglaries  burglPerPop  larcenies  larcPerPop  autoTheft  autoTheftPerPop  \\\n",
       "0          14       114.85        138     1132.08         16           131.26   \n",
       "1          57       242.37        376     1598.78         26           110.55   \n",
       "2         274       758.14       1797     4972.19        136            376.3   \n",
       "3         225      1301.78        716     4142.56         47           271.93   \n",
       "4          91       728.93       1060     8490.87         91           728.93   \n",
       "\n",
       "   arsons  arsonsPerPop  ViolentCrimesPerPop  nonViolPerPop  \n",
       "0       2         16.41                41.02        1394.59  \n",
       "1       1          4.25               127.56        1955.95  \n",
       "2      22         60.87               218.59        6167.51  \n",
       "3       ?             ?               306.64              ?  \n",
       "4       5         40.05                    ?        9988.79  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = contents_list # add headers with correct variable names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyVarNames = [ v[2] for v in varNames ] # get the variables that we don't use bc they have too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2215, 147), (2215, 104))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(onlyVarNames+['communityname', 'state'], axis=1) # drop vars that have a lot of NAs\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>murders</th>\n",
       "      <th>murdPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>...</td>\n",
       "      <td>53.72</td>\n",
       "      <td>65.29</td>\n",
       "      <td>78.09</td>\n",
       "      <td>89.14</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>...</td>\n",
       "      <td>77.17</td>\n",
       "      <td>71.27</td>\n",
       "      <td>90.22</td>\n",
       "      <td>96.12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.35</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>...</td>\n",
       "      <td>44.77</td>\n",
       "      <td>36.60</td>\n",
       "      <td>61.26</td>\n",
       "      <td>82.85</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2780.9</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>...</td>\n",
       "      <td>88.71</td>\n",
       "      <td>56.70</td>\n",
       "      <td>90.17</td>\n",
       "      <td>96.24</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3217.7</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>...</td>\n",
       "      <td>73.75</td>\n",
       "      <td>42.22</td>\n",
       "      <td>60.34</td>\n",
       "      <td>89.02</td>\n",
       "      <td>11.5</td>\n",
       "      <td>974.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>140494</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.51</td>\n",
       "      <td>95.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>18.09</td>\n",
       "      <td>32.89</td>\n",
       "      <td>20.04</td>\n",
       "      <td>...</td>\n",
       "      <td>64.35</td>\n",
       "      <td>42.29</td>\n",
       "      <td>70.61</td>\n",
       "      <td>85.66</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1995.7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>28700</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>96.57</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.10</td>\n",
       "      <td>11.17</td>\n",
       "      <td>27.41</td>\n",
       "      <td>12.76</td>\n",
       "      <td>...</td>\n",
       "      <td>77.30</td>\n",
       "      <td>63.45</td>\n",
       "      <td>82.23</td>\n",
       "      <td>93.53</td>\n",
       "      <td>10.9</td>\n",
       "      <td>2643.5</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>59459</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.20</td>\n",
       "      <td>84.87</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.63</td>\n",
       "      <td>15.31</td>\n",
       "      <td>27.93</td>\n",
       "      <td>14.78</td>\n",
       "      <td>...</td>\n",
       "      <td>73.70</td>\n",
       "      <td>54.85</td>\n",
       "      <td>85.55</td>\n",
       "      <td>91.51</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1515.3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>74111</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>97.11</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.73</td>\n",
       "      <td>16.64</td>\n",
       "      <td>35.16</td>\n",
       "      <td>20.33</td>\n",
       "      <td>...</td>\n",
       "      <td>58.82</td>\n",
       "      <td>40.72</td>\n",
       "      <td>67.97</td>\n",
       "      <td>81.39</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2399.3</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>103590</td>\n",
       "      <td>2.62</td>\n",
       "      <td>23.14</td>\n",
       "      <td>67.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16.35</td>\n",
       "      <td>19.88</td>\n",
       "      <td>34.55</td>\n",
       "      <td>21.62</td>\n",
       "      <td>...</td>\n",
       "      <td>75.59</td>\n",
       "      <td>42.33</td>\n",
       "      <td>74.05</td>\n",
       "      <td>92.12</td>\n",
       "      <td>78.5</td>\n",
       "      <td>1319.3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6.57</td>\n",
       "      <td>29</td>\n",
       "      <td>26.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0     1       11980           3.10          1.37         91.78          6.50   \n",
       "1     1       23123           2.82          0.80         95.57          3.44   \n",
       "2     1       29344           2.43          0.74         94.33          3.43   \n",
       "3     1       16656           2.40          1.70         97.35          0.50   \n",
       "4     1       11245           2.76          0.53         89.16          1.17   \n",
       "5     1      140494           2.45          2.51         95.65          0.90   \n",
       "6     1       28700           2.60          1.60         96.57          1.47   \n",
       "7     1       59459           2.45         14.20         84.87          0.40   \n",
       "8     1       74111           2.46          0.35         97.11          1.25   \n",
       "9     1      103590           2.62         23.14         67.60          0.92   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24     ...      \\\n",
       "0         1.88        12.47        21.44        10.93     ...       \n",
       "1         0.85        11.01        21.30        10.48     ...       \n",
       "2         2.35        11.36        25.88        11.01     ...       \n",
       "3         0.70        12.55        25.20        12.19     ...       \n",
       "4         0.52        24.46        40.53        28.69     ...       \n",
       "5         0.95        18.09        32.89        20.04     ...       \n",
       "6         1.10        11.17        27.41        12.76     ...       \n",
       "7         0.63        15.31        27.93        14.78     ...       \n",
       "8         0.73        16.64        35.16        20.33     ...       \n",
       "9        16.35        19.88        34.55        21.62     ...       \n",
       "\n",
       "   PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  LandArea  \\\n",
       "0             53.72           65.29          78.09           89.14       6.5   \n",
       "1             77.17           71.27          90.22           96.12      10.6   \n",
       "2             44.77           36.60          61.26           82.85      10.6   \n",
       "3             88.71           56.70          90.17           96.24       5.2   \n",
       "4             73.75           42.22          60.34           89.02      11.5   \n",
       "5             64.35           42.29          70.61           85.66      70.4   \n",
       "6             77.30           63.45          82.23           93.53      10.9   \n",
       "7             73.70           54.85          85.55           91.51      39.2   \n",
       "8             58.82           40.72          67.97           81.39      30.9   \n",
       "9             75.59           42.33          74.05           92.12      78.5   \n",
       "\n",
       "   PopDens  PctUsePubTrans  LemasPctOfficDrugUn  murders  murdPerPop  \n",
       "0   1845.9            9.63                 0.00        0        0.00  \n",
       "1   2186.7            3.84                 0.00        0        0.00  \n",
       "2   2780.9            4.37                 0.00        3        8.30  \n",
       "3   3217.7            3.31                 0.00        0        0.00  \n",
       "4    974.2            0.38                 0.00        0        0.00  \n",
       "5   1995.7            0.97                 0.00        7        4.63  \n",
       "6   2643.5            9.62                 0.00        0        0.00  \n",
       "7   1515.3            0.70                 0.00        8       13.13  \n",
       "8   2399.3            1.41                 0.00        0        0.00  \n",
       "9   1319.3            0.76                 6.57       29       26.88  \n",
       "\n",
       "[10 rows x 104 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 104)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that there are no '?'s (NAs)\n",
    "df2 = df2.replace('?', np.nan)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1994, 104), (1994,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2[df.ViolentCrimesPerPop != '?'] # didn't get rid of '?' in the y (ViolentCrimesPerPop) yet\n",
    "y = df.ViolentCrimesPerPop[df.ViolentCrimesPerPop != '?']\n",
    "y = pd.Series([float(a) > AVG_CRIME for a in y ]) # make the y 0 or 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.dtypes # check that datatypes are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1595, 104), (399, 104), (1595,), (399,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=364)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest \n",
    "cm1 = confusion_matrix(y_test, predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.87218045,  0.87218045]),\n",
       " 'FDR': array([ 0.1137931 ,  0.16513761]),\n",
       " 'FNR': array([ 0.06545455,  0.26612903]),\n",
       " 'FPR': array([ 0.26612903,  0.06545455]),\n",
       " 'NPV': array([ 0.83486239,  0.8862069 ]),\n",
       " 'PPV': array([ 0.8862069 ,  0.83486239]),\n",
       " 'TNR': array([ 0.73387097,  0.93454545]),\n",
       " 'TPR': array([ 0.93454545,  0.73387097])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_measures(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861083249749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.93      0.90      1362\n",
      "       True       0.83      0.71      0.76       632\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest w/ CV\n",
    "predicted_rf_cv = cross_validation.cross_val_predict(RandomForestClassifier(n_estimators=20), X, y, cv=10)\n",
    "print(metrics.accuracy_score(y, predicted_rf_cv))\n",
    "print(metrics.classification_report(y, predicted_rf_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': array([ 0.86108325,  0.86108325]),\n",
       " 'FDR': array([ 0.12611992,  0.17311234]),\n",
       " 'FNR': array([ 0.06901615,  0.28955696]),\n",
       " 'FPR': array([ 0.28955696,  0.06901615]),\n",
       " 'NPV': array([ 0.82688766,  0.87388008]),\n",
       " 'PPV': array([ 0.87388008,  0.82688766]),\n",
       " 'TNR': array([ 0.71044304,  0.93098385]),\n",
       " 'TPR': array([ 0.93098385,  0.71044304])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1b = confusion_matrix(y, predicted_rf_cv)\n",
    "statistical_measures(cm1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm_analysis(confusion_matrix):\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    TN = confusion_matrix[0][0]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return {'true positive':TPR, 'true negative':TNR, 'precision':PPV, 'negative predictive val':NPV, 'false positive':FPR, 'false negative':FNR, 'false discovery':FDR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_analysis(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistical_measures(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
